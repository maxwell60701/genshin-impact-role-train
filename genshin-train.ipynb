{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-10T04:02:58.471336Z",
     "iopub.status.busy": "2025-05-10T04:02:58.470939Z",
     "iopub.status.idle": "2025-05-10T04:03:29.676208Z",
     "shell.execute_reply": "2025-05-10T04:03:29.675602Z",
     "shell.execute_reply.started": "2025-05-10T04:02:58.471281Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://repo.huaweicloud.com/repository/pypi/simple\n",
      "Collecting transformers>=4.46.3 (from -r requirements.txt (line 1))\n",
      "  Downloading https://repo.huaweicloud.com/repository/pypi/packages/a9/b6/5257d04ae327b44db31f15cce39e6020cc986333c715660b1315a9724d82/transformers-4.51.3-py3-none-any.whl (10.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m56.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting datasets>=3.4.1 (from -r requirements.txt (line 2))\n",
      "  Downloading https://repo.huaweicloud.com/repository/pypi/packages/20/34/a08b0ee99715eaba118cbe19a71f7b5e2425c2718ef96007c325944a1152/datasets-3.6.0-py3-none-any.whl (491 kB)\n",
      "Collecting accelerate==1.5.2 (from -r requirements.txt (line 3))\n",
      "  Downloading https://repo.huaweicloud.com/repository/pypi/packages/70/83/167d4b638bb758a966828eb8d23c5e7047825edfdf768ff5f4fb01440063/accelerate-1.5.2-py3-none-any.whl (345 kB)\n",
      "Collecting peft==0.14.0 (from -r requirements.txt (line 4))\n",
      "  Downloading https://repo.huaweicloud.com/repository/pypi/packages/88/05/e58e3aaa36544d30a917814e336fc65a746f708e5874945e92999bc22fa3/peft-0.14.0-py3-none-any.whl (374 kB)\n",
      "Collecting trl==0.16.0 (from -r requirements.txt (line 5))\n",
      "  Downloading https://repo.huaweicloud.com/repository/pypi/packages/ea/ee/1a18222044df9e7377338a3c0d774c7b10e8b076f253006096247e7be095/trl-0.16.0-py3-none-any.whl (335 kB)\n",
      "Collecting tokenizers==0.20.3 (from -r requirements.txt (line 6))\n",
      "  Downloading https://repo.huaweicloud.com/repository/pypi/packages/aa/49/15fae66ac62e49255eeedbb7f4127564b2c3f3aef2009913f525732d1a08/tokenizers-0.20.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m99.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting gradio==5.20.0 (from -r requirements.txt (line 7))\n",
      "  Downloading https://repo.huaweicloud.com/repository/pypi/packages/dd/45/64acd7bed4abe64358c8ffa5256d6d25f54cc7b87c43fcaeda1b94ba243e/gradio-5.20.0-py3-none-any.whl (62.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 MB\u001b[0m \u001b[31m43.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pandas==2.2.3 in /usr/local/lib/python3.10/site-packages (from -r requirements.txt (line 8)) (2.2.3)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/site-packages (from -r requirements.txt (line 9)) (1.15.2)\n",
      "Collecting einops (from -r requirements.txt (line 10))\n",
      "  Downloading https://repo.huaweicloud.com/repository/pypi/packages/87/62/9773de14fe6c45c23649e98b83231fffd7b9892b6cf863251dc2afa73643/einops-0.8.1-py3-none-any.whl (64 kB)\n",
      "Collecting sentencepiece (from -r requirements.txt (line 11))\n",
      "  Downloading https://repo.huaweicloud.com/repository/pypi/packages/a6/27/33019685023221ca8ed98e8ceb7ae5e166032686fa3662c68f1f1edf334e/sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m44.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tiktoken (from -r requirements.txt (line 12))\n",
      "  Downloading https://repo.huaweicloud.com/repository/pypi/packages/f1/95/cc2c6d79df8f113bdc6c99cdec985a878768120d87d839a34da4bd3ff90a/tiktoken-0.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.10/site-packages (from -r requirements.txt (line 13)) (6.30.2)\n",
      "Requirement already satisfied: uvicorn in /usr/local/lib/python3.10/site-packages (from -r requirements.txt (line 14)) (0.34.0)\n",
      "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/site-packages (from -r requirements.txt (line 15)) (2.10.3)\n",
      "Collecting fastapi (from -r requirements.txt (line 16))\n",
      "  Downloading https://repo.huaweicloud.com/repository/pypi/packages/50/b3/b51f09c2ba432a576fe63758bddc81f78f0c6309d9e5c10d194313bf021e/fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
      "Collecting sse-starlette (from -r requirements.txt (line 17))\n",
      "  Downloading https://repo.huaweicloud.com/repository/pypi/packages/43/a4/ee4a20f0b5ff34c391f3685eff7cdba1178a487766e31b04efb51bbddd87/sse_starlette-2.3.4-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: matplotlib==3.10.1 in /usr/local/lib/python3.10/site-packages (from -r requirements.txt (line 18)) (3.10.1)\n",
      "Collecting fire (from -r requirements.txt (line 19))\n",
      "  Downloading https://repo.huaweicloud.com/repository/pypi/packages/6b/b6/82c7e601d6d3c3278c40b7bd35e17e82aa227f050aa9f66cb7b7fce29471/fire-0.7.0.tar.gz (87 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/site-packages (from -r requirements.txt (line 20)) (24.2)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/site-packages (from -r requirements.txt (line 21)) (6.0.2)\n",
      "Collecting numpy==1.26.4 (from -r requirements.txt (line 22))\n",
      "  Downloading https://repo.huaweicloud.com/repository/pypi/packages/4b/d7/ecf66c1cd12dc28b4040b15ab4d17b773b87fa9d29ca16125de01adb36cd/numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hCollecting av (from -r requirements.txt (line 23))\n",
      "  Downloading https://repo.huaweicloud.com/repository/pypi/packages/4c/86/292aa2aee50902d55ea8cb94e6d6112d20884b340a6d75f8521f671c8556/av-14.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.7/34.7 MB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: librosa in /usr/local/lib/python3.10/site-packages (from -r requirements.txt (line 24)) (0.11.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/site-packages (from accelerate==1.5.2->-r requirements.txt (line 3)) (7.0.0)\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.10/site-packages (from accelerate==1.5.2->-r requirements.txt (line 3)) (2.6.0+cu124)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/site-packages (from accelerate==1.5.2->-r requirements.txt (line 3)) (0.30.2)\n",
      "Collecting safetensors>=0.4.3 (from accelerate==1.5.2->-r requirements.txt (line 3))\n",
      "  Downloading https://repo.huaweicloud.com/repository/pypi/packages/a6/f8/dae3421624fcc87a89d42e1898a798bc7ff72c61f38973a65d60df8f124c/safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/site-packages (from peft==0.14.0->-r requirements.txt (line 4)) (4.67.1)\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.10/site-packages (from trl==0.16.0->-r requirements.txt (line 5)) (13.9.4)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/site-packages (from gradio==5.20.0->-r requirements.txt (line 7)) (22.1.0)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/site-packages (from gradio==5.20.0->-r requirements.txt (line 7)) (4.9.0)\n",
      "Collecting ffmpy (from gradio==5.20.0->-r requirements.txt (line 7))\n",
      "  Downloading https://repo.huaweicloud.com/repository/pypi/packages/53/5d/65f40bd333463b3230b3a72d93873caaf49b0cbb5228598fafb75fcc5357/ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
      "Collecting gradio-client==1.7.2 (from gradio==5.20.0->-r requirements.txt (line 7))\n",
      "  Downloading https://repo.huaweicloud.com/repository/pypi/packages/95/cb/002424d4f5af1425f9cfe7dcee3ed795ed1367bf0f185a6c4bf81385e1d6/gradio_client-1.7.2-py3-none-any.whl (322 kB)\n",
      "Collecting groovy~=0.1 (from gradio==5.20.0->-r requirements.txt (line 7))\n",
      "  Downloading https://repo.huaweicloud.com/repository/pypi/packages/28/27/3d6dcadc8a3214d8522c1e7f6a19554e33659be44546d44a2f7572ac7d2a/groovy-0.1.2-py3-none-any.whl (14 kB)\n",
      "Collecting httpx>=0.24.1 (from gradio==5.20.0->-r requirements.txt (line 7))\n",
      "  Downloading https://repo.huaweicloud.com/repository/pypi/packages/2a/39/e50c7c3a983047577ee07d2a9e53faf5a69493943ec3f6a384bdc792deb2/httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/site-packages (from gradio==5.20.0->-r requirements.txt (line 7)) (3.1.6)\n",
      "Collecting markupsafe~=2.0 (from gradio==5.20.0->-r requirements.txt (line 7))\n",
      "  Downloading https://repo.huaweicloud.com/repository/pypi/packages/7c/52/2b1b570f6b8b803cef5ac28fdf78c0da318916c7d2fe9402a84d591b394c/MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
      "Collecting orjson~=3.0 (from gradio==5.20.0->-r requirements.txt (line 7))\n",
      "  Downloading https://repo.huaweicloud.com/repository/pypi/packages/8b/2f/0c646d5fd689d3be94f4d83fa9435a6c4322c9b8533edbb3cd4bc8c5f69a/orjson-3.10.18-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (132 kB)\n",
      "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.10/site-packages (from gradio==5.20.0->-r requirements.txt (line 7)) (11.1.0)\n",
      "Collecting pydub (from gradio==5.20.0->-r requirements.txt (line 7))\n",
      "  Downloading https://repo.huaweicloud.com/repository/pypi/packages/a6/53/d78dc063216e62fc55f6b2eebb447f6a4b0a59f55c8406376f76bf959b08/pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Collecting python-multipart>=0.0.18 (from gradio==5.20.0->-r requirements.txt (line 7))\n",
      "  Downloading https://repo.huaweicloud.com/repository/pypi/packages/45/58/38b5afbc1a800eeea951b9285d3912613f2603bdf897a4ab0f4bd7f405fc/python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
      "Collecting ruff>=0.9.3 (from gradio==5.20.0->-r requirements.txt (line 7))\n",
      "  Downloading https://repo.huaweicloud.com/repository/pypi/packages/4e/0b/c53a664f06e0faab596397867c6320c3816df479e888fe3af63bc3f89699/ruff-0.11.9-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting safehttpx<0.2.0,>=0.1.6 (from gradio==5.20.0->-r requirements.txt (line 7))\n",
      "  Downloading https://repo.huaweicloud.com/repository/pypi/packages/4d/c0/1108ad9f01567f66b3154063605b350b69c3c9366732e09e45f9fd0d1deb/safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
      "Collecting semantic-version~=2.0 (from gradio==5.20.0->-r requirements.txt (line 7))\n",
      "  Downloading https://repo.huaweicloud.com/repository/pypi/packages/6a/23/8146aad7d88f4fcb3a6218f41a60f6c2d4e3a72de72da1825dc7c8f7877c/semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Collecting starlette<1.0,>=0.40.0 (from gradio==5.20.0->-r requirements.txt (line 7))\n",
      "  Downloading https://repo.huaweicloud.com/repository/pypi/packages/8b/0c/9d30a4ebeb6db2b25a841afbb80f6ef9a854fc3b41be131d249a977b4959/starlette-0.46.2-py3-none-any.whl (72 kB)\n",
      "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio==5.20.0->-r requirements.txt (line 7))\n",
      "  Downloading https://repo.huaweicloud.com/repository/pypi/packages/f9/b6/a447b5e4ec71e13871be01ba81f5dfc9d0af7e473da256ff46bc0e24026f/tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/site-packages (from gradio==5.20.0->-r requirements.txt (line 7)) (0.12.5)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/site-packages (from gradio==5.20.0->-r requirements.txt (line 7)) (4.12.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/site-packages (from pandas==2.2.3->-r requirements.txt (line 8)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/site-packages (from pandas==2.2.3->-r requirements.txt (line 8)) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/site-packages (from pandas==2.2.3->-r requirements.txt (line 8)) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/site-packages (from matplotlib==3.10.1->-r requirements.txt (line 18)) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/site-packages (from matplotlib==3.10.1->-r requirements.txt (line 18)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/site-packages (from matplotlib==3.10.1->-r requirements.txt (line 18)) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/site-packages (from matplotlib==3.10.1->-r requirements.txt (line 18)) (1.4.8)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/site-packages (from matplotlib==3.10.1->-r requirements.txt (line 18)) (3.2.3)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/site-packages (from gradio-client==1.7.2->gradio==5.20.0->-r requirements.txt (line 7)) (2025.3.0)\n",
      "Collecting websockets<16.0,>=10.0 (from gradio-client==1.7.2->gradio==5.20.0->-r requirements.txt (line 7))\n",
      "  Downloading https://repo.huaweicloud.com/repository/pypi/packages/97/3a/5323a6bb94917af13bbb34009fac01e55c51dfde354f63692bf2533ffbc2/websockets-15.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (181 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from transformers>=4.46.3->-r requirements.txt (line 1)) (3.18.0)\n",
      "Collecting regex!=2019.12.17 (from transformers>=4.46.3->-r requirements.txt (line 1))\n",
      "  Downloading https://repo.huaweicloud.com/repository/pypi/packages/f2/98/26d3830875b53071f1f0ae6d547f1d98e964dd29ad35cbf94439120bb67a/regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (781 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.7/781.7 kB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/site-packages (from transformers>=4.46.3->-r requirements.txt (line 1)) (2.32.3)\n",
      "INFO: pip is looking at multiple versions of transformers to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting transformers>=4.46.3 (from -r requirements.txt (line 1))\n",
      "  Downloading https://repo.huaweicloud.com/repository/pypi/packages/15/af/a3eb4449c8fdde24413555a66e9c100b669f4428fc829bad4ceb73472f4f/transformers-4.51.2-py3-none-any.whl (10.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading https://repo.huaweicloud.com/repository/pypi/packages/73/e0/f1fce1b2f31da4acfb858732d909209fdb10f65adda1e7af0c7ac74927a5/transformers-4.51.1-py3-none-any.whl (10.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading https://repo.huaweicloud.com/repository/pypi/packages/6f/db/7ee15028d5130929aa0b1b85bab6d8bafe806254d3b5c56c42a0066cceb8/transformers-4.51.0-py3-none-any.whl (10.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading https://repo.huaweicloud.com/repository/pypi/packages/aa/22/733a6fc4a6445d835242f64c490fdd30f4a08d58f2b788613de3f9170692/transformers-4.50.3-py3-none-any.whl (10.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading https://repo.huaweicloud.com/repository/pypi/packages/f7/3c/41274bc4729e167021acd2aa41879bf0cf2c1911e77b0a0fa410c442307a/transformers-4.50.2-py3-none-any.whl (10.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading https://repo.huaweicloud.com/repository/pypi/packages/95/c9/a628fbff00c5fb542aa09c0cc66d86568dcc10e64be73005732f8988963b/transformers-4.50.1-py3-none-any.whl (10.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading https://repo.huaweicloud.com/repository/pypi/packages/75/b9/093543d741ddb7ccaeb655c8800968bd5cb42e26a51560287b00b4aa748b/transformers-4.50.0-py3-none-any.whl (10.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hINFO: pip is still looking at multiple versions of transformers to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading https://repo.huaweicloud.com/repository/pypi/packages/20/37/1f29af63e9c30156a3ed6ebc2754077016577c094f31de7b2631e5d379eb/transformers-4.49.0-py3-none-any.whl (10.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading https://repo.huaweicloud.com/repository/pypi/packages/b6/1a/efeecb8d83705f2f4beac98d46f2148c95ecd7babfb31b5c0f1e7017e83d/transformers-4.48.3-py3-none-any.whl (9.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading https://repo.huaweicloud.com/repository/pypi/packages/bd/40/902c95a2a6f5d2d120c940ac4bd1f937c01035af529803c13d65ca33c2d1/transformers-4.48.2-py3-none-any.whl (9.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading https://repo.huaweicloud.com/repository/pypi/packages/7b/9f/92d3091c44cb19add044064af1bf1345cd35fbb84d32a3690f912800a295/transformers-4.48.1-py3-none-any.whl (9.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading https://repo.huaweicloud.com/repository/pypi/packages/45/d6/a69764e89fc5c2c957aa473881527c8c35521108d553df703e9ba703daeb/transformers-4.48.0-py3-none-any.whl (9.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m44.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Downloading https://repo.huaweicloud.com/repository/pypi/packages/f2/3a/8bdab26e09c5a242182b7ba9152e216d5ab4ae2d78c4298eb4872549cd35/transformers-4.47.1-py3-none-any.whl (10.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading https://repo.huaweicloud.com/repository/pypi/packages/d0/a7/7eedcf6a359e1e1eff3bc204ad022485aa5d88c08e1e3e0e0aee8a2e2235/transformers-4.47.0-py3-none-any.whl (10.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading https://repo.huaweicloud.com/repository/pypi/packages/51/51/b87caa939fedf307496e4dbf412f4b909af3d9ca8b189fc3b65c1faa456f/transformers-4.46.3-py3-none-any.whl (10.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m51.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pyarrow>=15.0.0 (from datasets>=3.4.1->-r requirements.txt (line 2))\n",
      "  Downloading https://repo.huaweicloud.com/repository/pypi/packages/f1/ca/ae10fba419a6e94329707487835ec721f5a95f3ac9168500bcf7aa3813c7/pyarrow-20.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (42.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 MB\u001b[0m \u001b[31m44.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting dill<0.3.9,>=0.3.0 (from datasets>=3.4.1->-r requirements.txt (line 2))\n",
      "  Downloading https://repo.huaweicloud.com/repository/pypi/packages/c9/7a/cef76fd8438a42f96db64ddaa85280485a9c395e7df3db8158cfec1eee34/dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Collecting xxhash (from datasets>=3.4.1->-r requirements.txt (line 2))\n",
      "  Downloading https://repo.huaweicloud.com/repository/pypi/packages/f2/07/d9a3059f702dec5b3b703737afb6dda32f304f6e9da181a229dafd052c29/xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets>=3.4.1->-r requirements.txt (line 2))\n",
      "  Downloading https://repo.huaweicloud.com/repository/pypi/packages/bc/f7/7ec7fddc92e50714ea3745631f79bd9c96424cb2702632521028e57d3a36/multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/site-packages (from uvicorn->-r requirements.txt (line 14)) (8.1.8)\n",
      "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/site-packages (from uvicorn->-r requirements.txt (line 14)) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/site-packages (from pydantic->-r requirements.txt (line 15)) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/site-packages (from pydantic->-r requirements.txt (line 15)) (2.27.1)\n",
      "Collecting termcolor (from fire->-r requirements.txt (line 19))\n",
      "  Downloading https://repo.huaweicloud.com/repository/pypi/packages/4f/bd/de8d508070629b6d84a30d01d57e4a65c69aa7f5abe7560b8fad3b50ea59/termcolor-3.1.0-py3-none-any.whl (7.7 kB)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/site-packages (from librosa->-r requirements.txt (line 24)) (3.0.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/site-packages (from librosa->-r requirements.txt (line 24)) (0.61.2)\n",
      "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.10/site-packages (from librosa->-r requirements.txt (line 24)) (1.6.1)\n",
      "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.10/site-packages (from librosa->-r requirements.txt (line 24)) (1.4.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/site-packages (from librosa->-r requirements.txt (line 24)) (5.2.1)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/site-packages (from librosa->-r requirements.txt (line 24)) (0.13.1)\n",
      "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.10/site-packages (from librosa->-r requirements.txt (line 24)) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/site-packages (from librosa->-r requirements.txt (line 24)) (0.5.0.post1)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.10/site-packages (from librosa->-r requirements.txt (line 24)) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/site-packages (from librosa->-r requirements.txt (line 24)) (1.1.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio==5.20.0->-r requirements.txt (line 7)) (1.2.2)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio==5.20.0->-r requirements.txt (line 7)) (3.7)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio==5.20.0->-r requirements.txt (line 7)) (1.3.1)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->-r requirements.txt (line 2)) (3.11.16)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/site-packages (from httpx>=0.24.1->gradio==5.20.0->-r requirements.txt (line 7)) (2025.1.31)\n",
      "Collecting httpcore==1.* (from httpx>=0.24.1->gradio==5.20.0->-r requirements.txt (line 7))\n",
      "  Downloading https://repo.huaweicloud.com/repository/pypi/packages/7e/f5/f66802a942d491edb555dd61e3a9961140fd64c90bce1eafd741609d334d/httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Collecting h11>=0.8 (from uvicorn->-r requirements.txt (line 14))\n",
      "  Downloading https://repo.huaweicloud.com/repository/pypi/packages/04/4b/29cac41a4d98d144bf5f6d33995617b185d14b22401f75ca86f384e87ff1/h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /usr/local/lib/python3.10/site-packages (from numba>=0.51.0->librosa->-r requirements.txt (line 24)) (0.44.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/site-packages (from pooch>=1.1->librosa->-r requirements.txt (line 24)) (3.10.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas==2.2.3->-r requirements.txt (line 8)) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/site-packages (from requests->transformers>=4.46.3->-r requirements.txt (line 1)) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests->transformers>=4.46.3->-r requirements.txt (line 1)) (2.3.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/site-packages (from scikit-learn>=1.1.0->librosa->-r requirements.txt (line 24)) (3.6.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/site-packages (from soundfile>=0.12.1->librosa->-r requirements.txt (line 24)) (1.17.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.5.2->-r requirements.txt (line 3)) (3.4.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.5.2->-r requirements.txt (line 3)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.5.2->-r requirements.txt (line 3)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.5.2->-r requirements.txt (line 3)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.5.2->-r requirements.txt (line 3)) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.5.2->-r requirements.txt (line 3)) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.5.2->-r requirements.txt (line 3)) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.5.2->-r requirements.txt (line 3)) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.5.2->-r requirements.txt (line 3)) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.5.2->-r requirements.txt (line 3)) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.5.2->-r requirements.txt (line 3)) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.5.2->-r requirements.txt (line 3)) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.5.2->-r requirements.txt (line 3)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.5.2->-r requirements.txt (line 3)) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.5.2->-r requirements.txt (line 3)) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.5.2->-r requirements.txt (line 3)) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/site-packages (from sympy==1.13.1->torch>=2.0.0->accelerate==1.5.2->-r requirements.txt (line 3)) (1.3.0)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio==5.20.0->-r requirements.txt (line 7)) (1.5.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/site-packages (from rich->trl==0.16.0->-r requirements.txt (line 5)) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/site-packages (from rich->trl==0.16.0->-r requirements.txt (line 5)) (2.15.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->-r requirements.txt (line 2)) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->-r requirements.txt (line 2)) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->-r requirements.txt (line 2)) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->-r requirements.txt (line 2)) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->-r requirements.txt (line 2)) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->-r requirements.txt (line 2)) (6.4.2)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->-r requirements.txt (line 2)) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->-r requirements.txt (line 2)) (1.19.0)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa->-r requirements.txt (line 24)) (2.21)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->trl==0.16.0->-r requirements.txt (line 5)) (0.1.0)\n",
      "Building wheels for collected packages: fire\n",
      "  Building wheel for fire (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fire: filename=fire-0.7.0-py3-none-any.whl size=114331 sha256=d88dc6eba88a26687ad4408fc085c825f5f43f937f8da8f2ba01e89a5e76eb47\n",
      "  Stored in directory: /root/.cache/pip/wheels/b4/0e/e8/a8aa66217f7b50e1cde38571368552cc0b5b3f74d64d0a6b07\n",
      "Successfully built fire\n",
      "Installing collected packages: sentencepiece, pydub, xxhash, websockets, tomlkit, termcolor, semantic-version, safetensors, ruff, regex, python-multipart, pyarrow, orjson, numpy, markupsafe, h11, groovy, ffmpy, einops, dill, av, tiktoken, starlette, multiprocess, httpcore, fire, tokenizers, sse-starlette, httpx, fastapi, transformers, safehttpx, gradio-client, accelerate, peft, gradio, datasets, trl\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.2.4\n",
      "    Uninstalling numpy-2.2.4:\n",
      "      Successfully uninstalled numpy-2.2.4\n",
      "  Attempting uninstall: markupsafe\n",
      "    Found existing installation: MarkupSafe 3.0.2\n",
      "    Uninstalling MarkupSafe-3.0.2:\n",
      "      Successfully uninstalled MarkupSafe-3.0.2\n",
      "  Attempting uninstall: h11\n",
      "    Found existing installation: h11 0.14.0\n",
      "    Uninstalling h11-0.14.0:\n",
      "      Successfully uninstalled h11-0.14.0\n",
      "Successfully installed accelerate-1.5.2 av-14.3.0 datasets-3.6.0 dill-0.3.8 einops-0.8.1 fastapi-0.115.12 ffmpy-0.5.0 fire-0.7.0 gradio-5.20.0 gradio-client-1.7.2 groovy-0.1.2 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 markupsafe-2.1.5 multiprocess-0.70.16 numpy-1.26.4 orjson-3.10.18 peft-0.14.0 pyarrow-20.0.0 pydub-0.25.1 python-multipart-0.0.20 regex-2024.11.6 ruff-0.11.9 safehttpx-0.1.6 safetensors-0.5.3 semantic-version-2.10.0 sentencepiece-0.2.0 sse-starlette-2.3.4 starlette-0.46.2 termcolor-3.1.0 tiktoken-0.9.0 tokenizers-0.20.3 tomlkit-0.13.2 transformers-4.46.3 trl-0.16.0 websockets-15.0.1 xxhash-3.5.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T04:03:29.677793Z",
     "iopub.status.busy": "2025-05-10T04:03:29.677539Z",
     "iopub.status.idle": "2025-05-10T04:03:31.256291Z",
     "shell.execute_reply": "2025-05-10T04:03:31.254672Z",
     "shell.execute_reply.started": "2025-05-10T04:03:29.677771Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "Device count: 1\n",
      "Device name: NVIDIA GeForce RTX 4090\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"HF_ENDPOINT\"] = \"https://hf-mirror.com\"\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"Device count:\", torch.cuda.device_count())\n",
    "print(\"Device name:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T04:03:31.258670Z",
     "iopub.status.busy": "2025-05-10T04:03:31.258146Z",
     "iopub.status.idle": "2025-05-10T04:04:02.630374Z",
     "shell.execute_reply": "2025-05-10T04:04:02.629338Z",
     "shell.execute_reply.started": "2025-05-10T04:03:31.258629Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92b00cae97a549de82cc0c90e63b8257",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LlamaTokenizerFast(name_or_path='deepseek-ai/DeepSeek-R1-Distill-Qwen-7B', vocab_size=151643, model_max_length=16384, is_fast=True, padding_side='left', truncation_side='right', special_tokens={'bos_token': '<｜begin▁of▁sentence｜>', 'eos_token': '<｜end▁of▁sentence｜>', 'pad_token': '<｜end▁of▁sentence｜>'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
      "\t151643: AddedToken(\"<｜end▁of▁sentence｜>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151644: AddedToken(\"<｜User｜>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t151645: AddedToken(\"<｜Assistant｜>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t151646: AddedToken(\"<｜begin▁of▁sentence｜>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151647: AddedToken(\"<|EOT|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t151648: AddedToken(\"<think>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t151649: AddedToken(\"</think>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t151650: AddedToken(\"<|quad_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151651: AddedToken(\"<|quad_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151652: AddedToken(\"<|vision_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151653: AddedToken(\"<|vision_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151654: AddedToken(\"<|vision_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151655: AddedToken(\"<|image_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151656: AddedToken(\"<|video_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151657: AddedToken(\"<tool_call>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t151658: AddedToken(\"</tool_call>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t151659: AddedToken(\"<|fim_prefix|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t151660: AddedToken(\"<|fim_middle|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t151661: AddedToken(\"<|fim_suffix|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t151662: AddedToken(\"<|fim_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t151663: AddedToken(\"<|repo_name|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t151664: AddedToken(\"<|file_sep|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "check_point='deepseek-ai/DeepSeek-R1-Distill-Qwen-7B'\n",
    "tokenizer = AutoTokenizer.from_pretrained(check_point)\n",
    "model = AutoModelForCausalLM.from_pretrained(check_point, torch_dtype=torch.float16,device_map=\"auto\")\n",
    "print(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T04:04:02.631781Z",
     "iopub.status.busy": "2025-05-10T04:04:02.631514Z",
     "iopub.status.idle": "2025-05-10T04:04:03.183711Z",
     "shell.execute_reply": "2025-05-10T04:04:03.182017Z",
     "shell.execute_reply.started": "2025-05-10T04:04:02.631763Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat May 10 04:04:02 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.144.03             Driver Version: 550.144.03     CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4090        On  |   00000000:81:00.0 Off |                  Off |\n",
      "| 30%   33C    P2             56W /  450W |   15090MiB /  24564MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T04:04:03.186761Z",
     "iopub.status.busy": "2025-05-10T04:04:03.185840Z",
     "iopub.status.idle": "2025-05-10T04:04:03.195211Z",
     "shell.execute_reply": "2025-05-10T04:04:03.194237Z",
     "shell.execute_reply.started": "2025-05-10T04:04:03.186716Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qwen2ForCausalLM(\n",
      "  (model): Qwen2Model(\n",
      "    (embed_tokens): Embedding(152064, 3584)\n",
      "    (layers): ModuleList(\n",
      "      (0-27): 28 x Qwen2DecoderLayer(\n",
      "        (self_attn): Qwen2SdpaAttention(\n",
      "          (q_proj): Linear(in_features=3584, out_features=3584, bias=True)\n",
      "          (k_proj): Linear(in_features=3584, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=3584, out_features=512, bias=True)\n",
      "          (o_proj): Linear(in_features=3584, out_features=3584, bias=False)\n",
      "          (rotary_emb): Qwen2RotaryEmbedding()\n",
      "        )\n",
      "        (mlp): Qwen2MLP(\n",
      "          (gate_proj): Linear(in_features=3584, out_features=18944, bias=False)\n",
      "          (up_proj): Linear(in_features=3584, out_features=18944, bias=False)\n",
      "          (down_proj): Linear(in_features=18944, out_features=3584, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
      "        (post_attention_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
      "      )\n",
      "    )\n",
      "    (norm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
      "    (rotary_emb): Qwen2RotaryEmbedding()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=3584, out_features=152064, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T04:04:03.197442Z",
     "iopub.status.busy": "2025-05-10T04:04:03.196696Z",
     "iopub.status.idle": "2025-05-10T04:04:03.250364Z",
     "shell.execute_reply": "2025-05-10T04:04:03.249157Z",
     "shell.execute_reply.started": "2025-05-10T04:04:03.197401Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151665\n",
      "151643\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(151666, 3584)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.add_special_tokens({\n",
    "    \"additional_special_tokens\": [\"<｜User｜>\", \"<｜Assistant｜>\"]\n",
    "})\n",
    "tokenizer.add_special_tokens({'pad_token': '<|pad|>'})\n",
    "tokenizer.pad_token = '<|pad|>'\n",
    "print(tokenizer.pad_token_id)\n",
    "print(tokenizer.eos_token_id)\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T04:04:03.254750Z",
     "iopub.status.busy": "2025-05-10T04:04:03.254359Z",
     "iopub.status.idle": "2025-05-10T04:04:03.259453Z",
     "shell.execute_reply": "2025-05-10T04:04:03.258419Z",
     "shell.execute_reply.started": "2025-05-10T04:04:03.254712Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LlamaTokenizerFast(name_or_path='deepseek-ai/DeepSeek-R1-Distill-Qwen-7B', vocab_size=151643, model_max_length=16384, is_fast=True, padding_side='left', truncation_side='right', special_tokens={'bos_token': '<｜begin▁of▁sentence｜>', 'eos_token': '<｜end▁of▁sentence｜>', 'pad_token': '<|pad|>', 'additional_special_tokens': ['<｜User｜>', '<｜Assistant｜>']}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
      "\t151643: AddedToken(\"<｜end▁of▁sentence｜>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151644: AddedToken(\"<｜User｜>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151645: AddedToken(\"<｜Assistant｜>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151646: AddedToken(\"<｜begin▁of▁sentence｜>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151647: AddedToken(\"<|EOT|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t151648: AddedToken(\"<think>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t151649: AddedToken(\"</think>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t151650: AddedToken(\"<|quad_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151651: AddedToken(\"<|quad_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151652: AddedToken(\"<|vision_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151653: AddedToken(\"<|vision_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151654: AddedToken(\"<|vision_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151655: AddedToken(\"<|image_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151656: AddedToken(\"<|video_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151657: AddedToken(\"<tool_call>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t151658: AddedToken(\"</tool_call>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t151659: AddedToken(\"<|fim_prefix|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t151660: AddedToken(\"<|fim_middle|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t151661: AddedToken(\"<|fim_suffix|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t151662: AddedToken(\"<|fim_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t151663: AddedToken(\"<|repo_name|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t151664: AddedToken(\"<|file_sep|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t151665: AddedToken(\"<|pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T04:04:03.261730Z",
     "iopub.status.busy": "2025-05-10T04:04:03.260865Z",
     "iopub.status.idle": "2025-05-10T04:04:09.291734Z",
     "shell.execute_reply": "2025-05-10T04:04:09.290549Z",
     "shell.execute_reply.started": "2025-05-10T04:04:03.261688Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since maxwell60701/genshin-impact-role-chat-model couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'default' at /output/huggingface/datasets/maxwell60701___genshin-impact-role-chat-model/default/0.0.0/2e804a4698e0dac30e5da8bf431249151072f447 (last modified on Fri May  9 09:26:48 2025).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['messages'],\n",
       "        num_rows: 4080\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['messages'],\n",
       "        num_rows: 1020\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "raw_datasets=load_dataset('maxwell60701/genshin-impact-role-chat-model',download_mode='force_redownload')\n",
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T04:04:09.294063Z",
     "iopub.status.busy": "2025-05-10T04:04:09.293454Z",
     "iopub.status.idle": "2025-05-10T04:04:09.302087Z",
     "shell.execute_reply": "2025-05-10T04:04:09.301008Z",
     "shell.execute_reply.started": "2025-05-10T04:04:09.294021Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [{'content': '妮露什么性别', 'role': 'user'},\n",
       "  {'content': '妮露是女性', 'role': 'assistant'}]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T04:04:09.304490Z",
     "iopub.status.busy": "2025-05-10T04:04:09.303473Z",
     "iopub.status.idle": "2025-05-10T04:04:09.311044Z",
     "shell.execute_reply": "2025-05-10T04:04:09.309878Z",
     "shell.execute_reply.started": "2025-05-10T04:04:09.304444Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'content': '妮露什么性别', 'role': 'user'},\n",
       " {'content': '妮露是女性', 'role': 'assistant'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets['train'][0]['messages']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T04:04:09.313115Z",
     "iopub.status.busy": "2025-05-10T04:04:09.312405Z",
     "iopub.status.idle": "2025-05-10T04:04:09.318294Z",
     "shell.execute_reply": "2025-05-10T04:04:09.317451Z",
     "shell.execute_reply.started": "2025-05-10T04:04:09.313075Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['messages'],\n",
       "    num_rows: 4080\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train_datasets=raw_datasets['train']\n",
    "raw_train_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T04:04:09.320254Z",
     "iopub.status.busy": "2025-05-10T04:04:09.319602Z",
     "iopub.status.idle": "2025-05-10T04:04:09.325669Z",
     "shell.execute_reply": "2025-05-10T04:04:09.324822Z",
     "shell.execute_reply.started": "2025-05-10T04:04:09.320214Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['messages'],\n",
       "    num_rows: 1020\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_test_datasets=raw_datasets['test']\n",
    "raw_test_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T04:04:09.327542Z",
     "iopub.status.busy": "2025-05-10T04:04:09.326936Z",
     "iopub.status.idle": "2025-05-10T04:04:09.331853Z",
     "shell.execute_reply": "2025-05-10T04:04:09.330930Z",
     "shell.execute_reply.started": "2025-05-10T04:04:09.327504Z"
    }
   },
   "outputs": [],
   "source": [
    "def tokenizer_convert(example):\n",
    "  prompt=tokenizer.apply_chat_template(example['messages'],tokenize=False)\n",
    "  return {'text':prompt}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T04:04:09.333889Z",
     "iopub.status.busy": "2025-05-10T04:04:09.333209Z",
     "iopub.status.idle": "2025-05-10T04:04:09.451034Z",
     "shell.execute_reply": "2025-05-10T04:04:09.450103Z",
     "shell.execute_reply.started": "2025-05-10T04:04:09.333849Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<｜begin▁of▁sentence｜><｜User｜>妮露什么性别<｜Assistant｜>妮露是女性<｜end▁of▁sentence｜>'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_datasets=raw_train_datasets.map(tokenizer_convert).remove_columns('messages')\n",
    "train_datasets[0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T04:04:09.452493Z",
     "iopub.status.busy": "2025-05-10T04:04:09.452225Z",
     "iopub.status.idle": "2025-05-10T04:04:09.554006Z",
     "shell.execute_reply": "2025-05-10T04:04:09.552930Z",
     "shell.execute_reply.started": "2025-05-10T04:04:09.452473Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<｜begin▁of▁sentence｜><｜User｜>班尼特用的是什么元素?<｜Assistant｜>火元素<｜end▁of▁sentence｜>'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_datasets=raw_test_datasets.map(tokenizer_convert).remove_columns('messages')\n",
    "test_datasets[0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T04:04:09.555445Z",
     "iopub.status.busy": "2025-05-10T04:04:09.555256Z",
     "iopub.status.idle": "2025-05-10T04:04:10.072234Z",
     "shell.execute_reply": "2025-05-10T04:04:10.071021Z",
     "shell.execute_reply.started": "2025-05-10T04:04:09.555426Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from transformers import TrainerCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T04:04:10.073808Z",
     "iopub.status.busy": "2025-05-10T04:04:10.073368Z",
     "iopub.status.idle": "2025-05-10T04:04:10.080442Z",
     "shell.execute_reply": "2025-05-10T04:04:10.079426Z",
     "shell.execute_reply.started": "2025-05-10T04:04:10.073788Z"
    }
   },
   "outputs": [],
   "source": [
    "class LossPlotCallback(TrainerCallback):\n",
    "    def __init__(self):\n",
    "        self.train_losses = []\n",
    "        self.eval_losses = []\n",
    "        self.train_epoch = []\n",
    "        self.eval_epoch = []\n",
    "\n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        if logs is None:\n",
    "            return\n",
    "        print(f\"self: {self}\", flush=True)\n",
    "        print(f\"logs: {logs}\", flush=True)\n",
    "        epoch = logs.get(\"epoch\")\n",
    "        if epoch is None:\n",
    "            return\n",
    "        if \"loss\" in logs:\n",
    "            self.train_epoch.append(epoch)\n",
    "            self.train_losses.append(logs[\"loss\"])\n",
    "        if \"eval_loss\" in logs:\n",
    "            self.eval_epoch.append(epoch)\n",
    "            self.eval_losses.append(logs[\"eval_loss\"])\n",
    "        self.plot_losses()\n",
    "\n",
    "    def plot_losses(self):\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(self.train_epoch, self.train_losses, label='Train Loss', marker='o')\n",
    "        plt.plot(self.eval_epoch, self.eval_losses, label='Eval Loss', marker='x')\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.title(\"Training & Evaluation Loss\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"loss_plot.png\")\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T04:04:10.081432Z",
     "iopub.status.busy": "2025-05-10T04:04:10.081267Z",
     "iopub.status.idle": "2025-05-10T04:04:10.543691Z",
     "shell.execute_reply": "2025-05-10T04:04:10.541965Z",
     "shell.execute_reply.started": "2025-05-10T04:04:10.081415Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from trl import SFTTrainer,SFTConfig\n",
    "\n",
    "training_args=SFTConfig(\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=8,\n",
    "    gradient_checkpointing=True,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    bf16=True,\n",
    "    logging_steps=10,\n",
    "    output_dir=\"./\",\n",
    "    save_strategy=\"epoch\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    num_train_epochs=10,\n",
    "    learning_rate=5e-5,\n",
    "    save_steps=100,\n",
    "    push_to_hub=False,\n",
    "    dataset_text_field=\"text\",\n",
    "    report_to=\"none\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T04:04:10.546293Z",
     "iopub.status.busy": "2025-05-10T04:04:10.545572Z",
     "iopub.status.idle": "2025-05-10T04:04:10.552294Z",
     "shell.execute_reply": "2025-05-10T04:04:10.551199Z",
     "shell.execute_reply.started": "2025-05-10T04:04:10.546250Z"
    }
   },
   "outputs": [],
   "source": [
    "from peft import LoraConfig,get_peft_model\n",
    "peft_config=LoraConfig(\n",
    "    r=32,  \n",
    "    lora_alpha=64,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    target_modules=[\"embed_tokens\", \"lm_head\",\"q_proj\",\"k_proj\",\"v_proj\",\"o_proj\"],\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T04:04:10.554592Z",
     "iopub.status.busy": "2025-05-10T04:04:10.553820Z",
     "iopub.status.idle": "2025-05-10T04:04:10.562530Z",
     "shell.execute_reply": "2025-05-10T04:04:10.561560Z",
     "shell.execute_reply.started": "2025-05-10T04:04:10.554551Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataCollatorForCompletionOnlyLM(tokenizer=LlamaTokenizerFast(name_or_path='deepseek-ai/DeepSeek-R1-Distill-Qwen-7B', vocab_size=151643, model_max_length=16384, is_fast=True, padding_side='left', truncation_side='right', special_tokens={'bos_token': '<｜begin▁of▁sentence｜>', 'eos_token': '<｜end▁of▁sentence｜>', 'pad_token': '<|pad|>', 'additional_special_tokens': ['<｜User｜>', '<｜Assistant｜>']}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
       "\t151643: AddedToken(\"<｜end▁of▁sentence｜>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151644: AddedToken(\"<｜User｜>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151645: AddedToken(\"<｜Assistant｜>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151646: AddedToken(\"<｜begin▁of▁sentence｜>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151647: AddedToken(\"<|EOT|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151648: AddedToken(\"<think>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151649: AddedToken(\"</think>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151650: AddedToken(\"<|quad_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151651: AddedToken(\"<|quad_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151652: AddedToken(\"<|vision_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151653: AddedToken(\"<|vision_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151654: AddedToken(\"<|vision_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151655: AddedToken(\"<|image_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151656: AddedToken(\"<|video_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151657: AddedToken(\"<tool_call>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151658: AddedToken(\"</tool_call>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151659: AddedToken(\"<|fim_prefix|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151660: AddedToken(\"<|fim_middle|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151661: AddedToken(\"<|fim_suffix|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151662: AddedToken(\"<|fim_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151663: AddedToken(\"<|repo_name|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151664: AddedToken(\"<|file_sep|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151665: AddedToken(\"<|pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}, mlm=False, mlm_probability=0.15, pad_to_multiple_of=None, tf_experimental_compile=False, return_tensors='pt')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from trl import DataCollatorForCompletionOnlyLM\n",
    "data_collator = DataCollatorForCompletionOnlyLM(\n",
    "    tokenizer=tokenizer,\n",
    "    instruction_template=\"<｜User｜>\",\n",
    "    response_template = \"<｜Assistant｜>\",\n",
    ")\n",
    "data_collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T04:04:10.564815Z",
     "iopub.status.busy": "2025-05-10T04:04:10.563962Z",
     "iopub.status.idle": "2025-05-10T04:04:11.609266Z",
     "shell.execute_reply": "2025-05-10T04:04:11.608375Z",
     "shell.execute_reply.started": "2025-05-10T04:04:10.564774Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import EvalPrediction\n",
    "\n",
    "def compute_metrics_fn(eval_pred: EvalPrediction) -> dict:\n",
    "    predictions, labels = eval_pred.predictions, eval_pred.label_ids\n",
    "    # 将预测结果转换为类别索引\n",
    "    preds = predictions.argmax(axis=-1)\n",
    "    # 计算准确率\n",
    "    accuracy = (preds == labels).mean()\n",
    "    return {\"accuracy\": accuracy}\n",
    "\n",
    "trainer=SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_datasets,\n",
    "    eval_dataset=test_datasets,\n",
    "    args=training_args,\n",
    "    peft_config=peft_config,\n",
    "    processing_class=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    callbacks=[LossPlotCallback()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T04:04:11.612167Z",
     "iopub.status.busy": "2025-05-10T04:04:11.611990Z",
     "iopub.status.idle": "2025-05-10T04:04:11.654578Z",
     "shell.execute_reply": "2025-05-10T04:04:11.653860Z",
     "shell.execute_reply.started": "2025-05-10T04:04:11.612150Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665,\n",
      "         151665, 151665, 151646, 151646, 151644, 100222,  99687, 102227, 102021,\n",
      "         105319,     30, 151645, 100222,  99687, 102227,  20412,  47872,  99525,\n",
      "          99235, 151643],\n",
      "        [151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665,\n",
      "         151665, 151665, 151665, 151665, 151646, 151646, 151644, 100222, 104654,\n",
      "          99316, 104139, 102625, 104363,     30, 151645, 111548,   9370, 117216,\n",
      "          99253, 151643],\n",
      "        [151646, 151646, 151644, 108386,     11, 109194, 101176, 102071,  99079,\n",
      "         104308, 102021, 105319,     30, 151645, 101176, 102071,  99079,  20412,\n",
      "          60686,  99208, 107891,  99305,  88970,  99347, 107891,   3837,  57750,\n",
      "         109753, 151643],\n",
      "        [151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665,\n",
      "         151665, 151665, 151665, 151646, 151646, 151644,  96465,  38212, 105198,\n",
      "         104308,  26232, 100359,  99245, 102268,  47534,     30, 151645,  96465,\n",
      "         102268, 151643]], device='cuda:0'), 'attention_mask': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1]], device='cuda:0'), 'labels': tensor([[  -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
      "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
      "           -100,   -100,   -100, 100222,  99687, 102227,  20412,  47872,  99525,\n",
      "          99235, 151643],\n",
      "        [  -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
      "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
      "           -100,   -100,   -100,   -100,   -100,   -100, 111548,   9370, 117216,\n",
      "          99253, 151643],\n",
      "        [  -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
      "           -100,   -100,   -100,   -100,   -100, 101176, 102071,  99079,  20412,\n",
      "          60686,  99208, 107891,  99305,  88970,  99347, 107891,   3837,  57750,\n",
      "         109753, 151643],\n",
      "        [  -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
      "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
      "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,  96465,\n",
      "         102268, 151643]], device='cuda:0')}\n"
     ]
    }
   ],
   "source": [
    "dataloader = trainer.get_train_dataloader()\n",
    "\n",
    "for batch in dataloader:\n",
    "    print(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T04:04:11.655518Z",
     "iopub.status.busy": "2025-05-10T04:04:11.655353Z",
     "iopub.status.idle": "2025-05-10T04:40:27.638276Z",
     "shell.execute_reply": "2025-05-10T04:40:27.637772Z",
     "shell.execute_reply.started": "2025-05-10T04:04:11.655502Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1270' max='1270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1270/1270 36:13, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.284100</td>\n",
       "      <td>0.956189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.049800</td>\n",
       "      <td>0.071135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.021000</td>\n",
       "      <td>0.019846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.010600</td>\n",
       "      <td>0.016001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.005300</td>\n",
       "      <td>0.018351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>0.018481</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 9.5683, 'grad_norm': 397.1864013671875, 'learning_rate': 4.999235143132708e-05, 'num_tokens': 6212.0, 'mean_token_accuracy': 0.25335838296450675, 'epoch': 0.0784313725490196}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 5.0606, 'grad_norm': 36.019432067871094, 'learning_rate': 4.996941040535653e-05, 'num_tokens': 12419.0, 'mean_token_accuracy': 0.35233423225581645, 'epoch': 0.1568627450980392}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 3.6494, 'grad_norm': 21.881195068359375, 'learning_rate': 4.993119095936937e-05, 'num_tokens': 18731.0, 'mean_token_accuracy': 0.48620745316147806, 'epoch': 0.23529411764705882}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 2.8581, 'grad_norm': 14.633879661560059, 'learning_rate': 4.9877716479290174e-05, 'num_tokens': 24899.0, 'mean_token_accuracy': 0.5812658857554197, 'epoch': 0.3137254901960784}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 2.4018, 'grad_norm': 12.14864730834961, 'learning_rate': 4.980901968537758e-05, 'num_tokens': 31197.0, 'mean_token_accuracy': 0.6264807648956776, 'epoch': 0.39215686274509803}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 2.2422, 'grad_norm': 10.657699584960938, 'learning_rate': 4.9725142612203265e-05, 'num_tokens': 37506.0, 'mean_token_accuracy': 0.6331018064171076, 'epoch': 0.47058823529411764}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 1.9533, 'grad_norm': 12.553037643432617, 'learning_rate': 4.962613658293158e-05, 'num_tokens': 43829.0, 'mean_token_accuracy': 0.6684237062931061, 'epoch': 0.5490196078431373}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 1.779, 'grad_norm': 10.541328430175781, 'learning_rate': 4.951206217791564e-05, 'num_tokens': 50075.0, 'mean_token_accuracy': 0.6793550111353397, 'epoch': 0.6274509803921569}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 1.4876, 'grad_norm': 13.164761543273926, 'learning_rate': 4.938298919762907e-05, 'num_tokens': 56364.0, 'mean_token_accuracy': 0.7314705736935139, 'epoch': 0.7058823529411765}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 1.4025, 'grad_norm': 14.701404571533203, 'learning_rate': 4.923899661995617e-05, 'num_tokens': 62472.0, 'mean_token_accuracy': 0.727974159270525, 'epoch': 0.7843137254901961}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 1.2316, 'grad_norm': 12.33759880065918, 'learning_rate': 4.908017255186643e-05, 'num_tokens': 68720.0, 'mean_token_accuracy': 0.7595274180173874, 'epoch': 0.8627450980392157}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 1.2841, 'grad_norm': 15.935413360595703, 'learning_rate': 4.890661417550319e-05, 'num_tokens': 74949.0, 'mean_token_accuracy': 0.7474692992866039, 'epoch': 0.9411764705882353}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'eval_loss': 0.9561890959739685, 'eval_runtime': 8.8862, 'eval_samples_per_second': 114.785, 'eval_steps_per_second': 14.404, 'eval_num_tokens': 79583.0, 'eval_mean_token_accuracy': 0.7948020151816308, 'epoch': 0.996078431372549}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/peft/utils/save_and_load.py:230: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 1.0362, 'grad_norm': 14.488682746887207, 'learning_rate': 4.871842768871928e-05, 'num_tokens': 81189.0, 'mean_token_accuracy': 0.8062988437712193, 'epoch': 1.0196078431372548}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.9013, 'grad_norm': 15.77553653717041, 'learning_rate': 4.85157282400961e-05, 'num_tokens': 87527.0, 'mean_token_accuracy': 0.8113073080778122, 'epoch': 1.0980392156862746}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.7643, 'grad_norm': 16.805570602416992, 'learning_rate': 4.829863985848587e-05, 'num_tokens': 93675.0, 'mean_token_accuracy': 0.8486723460257053, 'epoch': 1.1764705882352942}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.6902, 'grad_norm': 33.76056671142578, 'learning_rate': 4.806729537712017e-05, 'num_tokens': 99943.0, 'mean_token_accuracy': 0.8585738062858581, 'epoch': 1.2549019607843137}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.5956, 'grad_norm': 22.94242286682129, 'learning_rate': 4.782183635233124e-05, 'num_tokens': 106268.0, 'mean_token_accuracy': 0.8787535846233367, 'epoch': 1.3333333333333333}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.4996, 'grad_norm': 17.6942138671875, 'learning_rate': 4.756241297693566e-05, 'num_tokens': 112578.0, 'mean_token_accuracy': 0.8983473561704158, 'epoch': 1.4117647058823528}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.4513, 'grad_norm': 18.757579803466797, 'learning_rate': 4.728918398833361e-05, 'num_tokens': 118796.0, 'mean_token_accuracy': 0.9162268802523613, 'epoch': 1.4901960784313726}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.3697, 'grad_norm': 19.61395835876465, 'learning_rate': 4.7002316571379715e-05, 'num_tokens': 124942.0, 'mean_token_accuracy': 0.9279862120747566, 'epoch': 1.5686274509803921}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.2863, 'grad_norm': 14.765032768249512, 'learning_rate': 4.6701986256085046e-05, 'num_tokens': 130975.0, 'mean_token_accuracy': 0.9348849572241307, 'epoch': 1.6470588235294117}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.2749, 'grad_norm': 21.200910568237305, 'learning_rate': 4.6388376810212905e-05, 'num_tokens': 137263.0, 'mean_token_accuracy': 0.9438338860869407, 'epoch': 1.7254901960784315}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.2244, 'grad_norm': 12.708374977111816, 'learning_rate': 4.606168012683394e-05, 'num_tokens': 143507.0, 'mean_token_accuracy': 0.954550301283598, 'epoch': 1.803921568627451}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.1674, 'grad_norm': 12.070810317993164, 'learning_rate': 4.5722096106909595e-05, 'num_tokens': 149807.0, 'mean_token_accuracy': 0.9653525002300739, 'epoch': 1.8823529411764706}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.1438, 'grad_norm': 17.22356414794922, 'learning_rate': 4.536983253697561e-05, 'num_tokens': 155991.0, 'mean_token_accuracy': 0.972226332873106, 'epoch': 1.9607843137254903}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'eval_loss': 0.13272777199745178, 'eval_runtime': 8.8984, 'eval_samples_per_second': 114.628, 'eval_steps_per_second': 14.385, 'eval_num_tokens': 159166.0, 'eval_mean_token_accuracy': 0.9753036079928279, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/peft/utils/save_and_load.py:230: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.1104, 'grad_norm': 10.05060863494873, 'learning_rate': 4.5005104962000436e-05, 'num_tokens': 162301.0, 'mean_token_accuracy': 0.9818412624299526, 'epoch': 2.0392156862745097}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.0929, 'grad_norm': 13.306838035583496, 'learning_rate': 4.4628136553496375e-05, 'num_tokens': 168540.0, 'mean_token_accuracy': 0.9820419996976852, 'epoch': 2.1176470588235294}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.1036, 'grad_norm': 12.617330551147461, 'learning_rate': 4.423915797296425e-05, 'num_tokens': 174661.0, 'mean_token_accuracy': 0.9830658577382565, 'epoch': 2.196078431372549}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.0819, 'grad_norm': 12.255680084228516, 'learning_rate': 4.3838407230754885e-05, 'num_tokens': 180902.0, 'mean_token_accuracy': 0.9853940673172474, 'epoch': 2.2745098039215685}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.0656, 'grad_norm': 15.745244026184082, 'learning_rate': 4.34261295404341e-05, 'num_tokens': 187250.0, 'mean_token_accuracy': 0.9870502971112728, 'epoch': 2.3529411764705883}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.0642, 'grad_norm': 10.934918403625488, 'learning_rate': 4.300257716874001e-05, 'num_tokens': 193269.0, 'mean_token_accuracy': 0.9910536371171474, 'epoch': 2.431372549019608}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.0469, 'grad_norm': 9.919266700744629, 'learning_rate': 4.256800928122475e-05, 'num_tokens': 199523.0, 'mean_token_accuracy': 0.9912497699260712, 'epoch': 2.5098039215686274}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.067, 'grad_norm': 12.890610694885254, 'learning_rate': 4.2122691783674786e-05, 'num_tokens': 205798.0, 'mean_token_accuracy': 0.9904129303991794, 'epoch': 2.588235294117647}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.0451, 'grad_norm': 17.061809539794922, 'learning_rate': 4.1666897159406984e-05, 'num_tokens': 212043.0, 'mean_token_accuracy': 0.990634410828352, 'epoch': 2.6666666666666665}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.0529, 'grad_norm': 11.752535820007324, 'learning_rate': 4.1200904302540136e-05, 'num_tokens': 218331.0, 'mean_token_accuracy': 0.991324071586132, 'epoch': 2.7450980392156863}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.0479, 'grad_norm': 6.129230976104736, 'learning_rate': 4.072499834734357e-05, 'num_tokens': 224685.0, 'mean_token_accuracy': 0.9882638320326805, 'epoch': 2.8235294117647056}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.0331, 'grad_norm': 6.507317066192627, 'learning_rate': 4.0239470493767704e-05, 'num_tokens': 231085.0, 'mean_token_accuracy': 0.9960320815443993, 'epoch': 2.9019607843137254}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.0498, 'grad_norm': 4.650094032287598, 'learning_rate': 3.974461782926299e-05, 'num_tokens': 237193.0, 'mean_token_accuracy': 0.9910303331911564, 'epoch': 2.980392156862745}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'eval_loss': 0.0711350366473198, 'eval_runtime': 8.8844, 'eval_samples_per_second': 114.808, 'eval_steps_per_second': 14.407, 'eval_num_tokens': 238749.0, 'eval_mean_token_accuracy': 0.9857189171016216, 'epoch': 2.996078431372549}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/peft/utils/save_and_load.py:230: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.0452, 'grad_norm': 7.1327409744262695, 'learning_rate': 3.9240743146996425e-05, 'num_tokens': 243432.0, 'mean_token_accuracy': 0.9942624412477017, 'epoch': 3.0588235294117645}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.0533, 'grad_norm': 12.002632141113281, 'learning_rate': 3.8728154760576817e-05, 'num_tokens': 249710.0, 'mean_token_accuracy': 0.9906084381043911, 'epoch': 3.1372549019607843}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.0322, 'grad_norm': 4.376486778259277, 'learning_rate': 3.820716631540209e-05, 'num_tokens': 255914.0, 'mean_token_accuracy': 0.9926836125552654, 'epoch': 3.215686274509804}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.0304, 'grad_norm': 8.21672248840332, 'learning_rate': 3.767809659674433e-05, 'num_tokens': 262195.0, 'mean_token_accuracy': 0.9940428994596004, 'epoch': 3.2941176470588234}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.031, 'grad_norm': 4.575623989105225, 'learning_rate': 3.714126933468959e-05, 'num_tokens': 268417.0, 'mean_token_accuracy': 0.9939147405326366, 'epoch': 3.372549019607843}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.0183, 'grad_norm': 2.0829131603240967, 'learning_rate': 3.659701300605224e-05, 'num_tokens': 274797.0, 'mean_token_accuracy': 0.9963818252086639, 'epoch': 3.450980392156863}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.0224, 'grad_norm': 10.948628425598145, 'learning_rate': 3.604566063338467e-05, 'num_tokens': 280983.0, 'mean_token_accuracy': 0.9949231520295143, 'epoch': 3.5294117647058822}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.0277, 'grad_norm': 16.427772521972656, 'learning_rate': 3.548754958120573e-05, 'num_tokens': 287161.0, 'mean_token_accuracy': 0.9938305832445622, 'epoch': 3.607843137254902}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.023, 'grad_norm': 8.117752075195312, 'learning_rate': 3.492302134957218e-05, 'num_tokens': 293305.0, 'mean_token_accuracy': 0.9953900583088398, 'epoch': 3.686274509803922}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.0227, 'grad_norm': 6.796487808227539, 'learning_rate': 3.435242136511984e-05, 'num_tokens': 299509.0, 'mean_token_accuracy': 0.9953215323388577, 'epoch': 3.764705882352941}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.0238, 'grad_norm': 2.6026198863983154, 'learning_rate': 3.377609876970194e-05, 'num_tokens': 305657.0, 'mean_token_accuracy': 0.9956129014492034, 'epoch': 3.843137254901961}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.0281, 'grad_norm': 4.839510440826416, 'learning_rate': 3.319440620675442e-05, 'num_tokens': 312183.0, 'mean_token_accuracy': 0.9943808265030384, 'epoch': 3.9215686274509802}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.0359, 'grad_norm': 8.436041831970215, 'learning_rate': 3.26076996055184e-05, 'num_tokens': 318332.0, 'mean_token_accuracy': 0.9933279559016228, 'epoch': 4.0}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'eval_loss': 0.027484269812703133, 'eval_runtime': 8.8801, 'eval_samples_per_second': 114.863, 'eval_steps_per_second': 14.414, 'eval_num_tokens': 318332.0, 'eval_mean_token_accuracy': 0.9952681600116193, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/peft/utils/save_and_load.py:230: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.0131, 'grad_norm': 7.343189716339111, 'learning_rate': 3.201633796325233e-05, 'num_tokens': 324615.0, 'mean_token_accuracy': 0.997507418692112, 'epoch': 4.078431372549019}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.0193, 'grad_norm': 3.9138708114624023, 'learning_rate': 3.14206831255667e-05, 'num_tokens': 330683.0, 'mean_token_accuracy': 0.9968723602592945, 'epoch': 4.1568627450980395}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.0199, 'grad_norm': 2.761758327484131, 'learning_rate': 3.082109956501604e-05, 'num_tokens': 337136.0, 'mean_token_accuracy': 0.9974779054522515, 'epoch': 4.235294117647059}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.0119, 'grad_norm': 2.133014440536499, 'learning_rate': 3.0217954158083384e-05, 'num_tokens': 343445.0, 'mean_token_accuracy': 0.9982328437268734, 'epoch': 4.313725490196078}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.0105, 'grad_norm': 6.410921573638916, 'learning_rate': 2.96116159606939e-05, 'num_tokens': 349650.0, 'mean_token_accuracy': 0.9975266672670842, 'epoch': 4.392156862745098}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.0262, 'grad_norm': 7.475381374359131, 'learning_rate': 2.9002455982394944e-05, 'num_tokens': 355944.0, 'mean_token_accuracy': 0.9960961624979973, 'epoch': 4.470588235294118}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.0122, 'grad_norm': 6.329417705535889, 'learning_rate': 2.8390846959340638e-05, 'num_tokens': 362215.0, 'mean_token_accuracy': 0.9974435865879059, 'epoch': 4.549019607843137}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.011, 'grad_norm': 2.9058003425598145, 'learning_rate': 2.7777163126220118e-05, 'num_tokens': 368428.0, 'mean_token_accuracy': 0.997550968080759, 'epoch': 4.627450980392156}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.0088, 'grad_norm': 23.01593589782715, 'learning_rate': 2.7161779987268644e-05, 'num_tokens': 374629.0, 'mean_token_accuracy': 0.9986695758998394, 'epoch': 4.705882352941177}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.0282, 'grad_norm': 7.1313371658325195, 'learning_rate': 2.6545074086502108e-05, 'num_tokens': 380845.0, 'mean_token_accuracy': 0.9937966637313366, 'epoch': 4.784313725490196}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.0188, 'grad_norm': 1.779372215270996, 'learning_rate': 2.592742277731513e-05, 'num_tokens': 386941.0, 'mean_token_accuracy': 0.9962763793766498, 'epoch': 4.862745098039216}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.021, 'grad_norm': 6.697644233703613, 'learning_rate': 2.5309203991584073e-05, 'num_tokens': 393239.0, 'mean_token_accuracy': 0.9963204197585582, 'epoch': 4.9411764705882355}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'eval_loss': 0.019845742732286453, 'eval_runtime': 8.8909, 'eval_samples_per_second': 114.724, 'eval_steps_per_second': 14.397, 'eval_num_tokens': 397915.0, 'eval_mean_token_accuracy': 0.9957400322891772, 'epoch': 4.996078431372549}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/peft/utils/save_and_load.py:230: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.0129, 'grad_norm': 1.9823945760726929, 'learning_rate': 2.469079600841593e-05, 'num_tokens': 399487.0, 'mean_token_accuracy': 0.9963180713355542, 'epoch': 5.019607843137255}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.0145, 'grad_norm': 2.968132257461548, 'learning_rate': 2.407257722268487e-05, 'num_tokens': 405678.0, 'mean_token_accuracy': 0.9971662424504757, 'epoch': 5.098039215686274}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.0094, 'grad_norm': 0.27649053931236267, 'learning_rate': 2.34549259134979e-05, 'num_tokens': 411835.0, 'mean_token_accuracy': 0.9983831740915775, 'epoch': 5.176470588235294}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.0064, 'grad_norm': 0.1679699867963791, 'learning_rate': 2.2838220012731365e-05, 'num_tokens': 418112.0, 'mean_token_accuracy': 0.998986654728651, 'epoch': 5.254901960784314}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.0116, 'grad_norm': 1.9185556173324585, 'learning_rate': 2.2222836873779888e-05, 'num_tokens': 424355.0, 'mean_token_accuracy': 0.9971042729914188, 'epoch': 5.333333333333333}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.0172, 'grad_norm': 4.10638427734375, 'learning_rate': 2.1609153040659358e-05, 'num_tokens': 430681.0, 'mean_token_accuracy': 0.9965341262519359, 'epoch': 5.411764705882353}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.0095, 'grad_norm': 7.514303207397461, 'learning_rate': 2.0997544017605062e-05, 'num_tokens': 437046.0, 'mean_token_accuracy': 0.9973944544792175, 'epoch': 5.490196078431373}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.0079, 'grad_norm': 0.16635596752166748, 'learning_rate': 2.0388384039306106e-05, 'num_tokens': 443246.0, 'mean_token_accuracy': 0.9979687497019768, 'epoch': 5.568627450980392}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.0162, 'grad_norm': 10.245881080627441, 'learning_rate': 1.9782045841916625e-05, 'num_tokens': 449552.0, 'mean_token_accuracy': 0.996018185466528, 'epoch': 5.647058823529412}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.0151, 'grad_norm': 0.4702446460723877, 'learning_rate': 1.917890043498397e-05, 'num_tokens': 455773.0, 'mean_token_accuracy': 0.9967656642198562, 'epoch': 5.7254901960784315}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.0085, 'grad_norm': 0.4104841351509094, 'learning_rate': 1.8579316874433305e-05, 'num_tokens': 462060.0, 'mean_token_accuracy': 0.9983644664287568, 'epoch': 5.803921568627451}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.0075, 'grad_norm': 3.4525458812713623, 'learning_rate': 1.7983662036747682e-05, 'num_tokens': 468235.0, 'mean_token_accuracy': 0.9980384849011898, 'epoch': 5.882352941176471}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.0188, 'grad_norm': 0.11324945837259293, 'learning_rate': 1.7392300394481597e-05, 'num_tokens': 474416.0, 'mean_token_accuracy': 0.9951049529016018, 'epoch': 5.96078431372549}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'eval_loss': 0.017539065331220627, 'eval_runtime': 8.867, 'eval_samples_per_second': 115.033, 'eval_steps_per_second': 14.436, 'eval_num_tokens': 477498.0, 'eval_mean_token_accuracy': 0.996327992528677, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/peft/utils/save_and_load.py:230: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.0104, 'grad_norm': 5.396175384521484, 'learning_rate': 1.680559379324558e-05, 'num_tokens': 480601.0, 'mean_token_accuracy': 0.9978901885449887, 'epoch': 6.03921568627451}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.0075, 'grad_norm': 0.30516475439071655, 'learning_rate': 1.6223901230298062e-05, 'num_tokens': 486942.0, 'mean_token_accuracy': 0.9981725752353668, 'epoch': 6.117647058823529}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.0043, 'grad_norm': 5.8536529541015625, 'learning_rate': 1.564757863488017e-05, 'num_tokens': 493276.0, 'mean_token_accuracy': 0.9986726358532906, 'epoch': 6.196078431372549}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.007, 'grad_norm': 1.536850929260254, 'learning_rate': 1.5076978650427826e-05, 'num_tokens': 499704.0, 'mean_token_accuracy': 0.9989682383835315, 'epoch': 6.2745098039215685}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.0098, 'grad_norm': 1.2555456161499023, 'learning_rate': 1.4512450418794279e-05, 'num_tokens': 505835.0, 'mean_token_accuracy': 0.9978505834937096, 'epoch': 6.352941176470588}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.0115, 'grad_norm': 8.708067893981934, 'learning_rate': 1.3954339366615334e-05, 'num_tokens': 511969.0, 'mean_token_accuracy': 0.996351807564497, 'epoch': 6.431372549019608}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.0061, 'grad_norm': 7.212568759918213, 'learning_rate': 1.340298699394777e-05, 'num_tokens': 518091.0, 'mean_token_accuracy': 0.9977015867829323, 'epoch': 6.509803921568627}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.0022, 'grad_norm': 0.30943745374679565, 'learning_rate': 1.2858730665310409e-05, 'num_tokens': 524354.0, 'mean_token_accuracy': 0.9995967738330365, 'epoch': 6.588235294117647}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.0111, 'grad_norm': 0.1743057519197464, 'learning_rate': 1.2321903403255672e-05, 'num_tokens': 530515.0, 'mean_token_accuracy': 0.9971342958509922, 'epoch': 6.666666666666667}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.0106, 'grad_norm': 3.955061435699463, 'learning_rate': 1.1792833684597907e-05, 'num_tokens': 536643.0, 'mean_token_accuracy': 0.9965633153915405, 'epoch': 6.745098039215686}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.0093, 'grad_norm': 0.3498114347457886, 'learning_rate': 1.1271845239423196e-05, 'num_tokens': 543005.0, 'mean_token_accuracy': 0.9976580917835236, 'epoch': 6.823529411764706}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.0028, 'grad_norm': 4.177273273468018, 'learning_rate': 1.0759256853003578e-05, 'num_tokens': 549290.0, 'mean_token_accuracy': 0.9989499516785145, 'epoch': 6.901960784313726}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.0106, 'grad_norm': 0.18155086040496826, 'learning_rate': 1.0255382170737017e-05, 'num_tokens': 555522.0, 'mean_token_accuracy': 0.9970936492085457, 'epoch': 6.980392156862745}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'eval_loss': 0.016001051291823387, 'eval_runtime': 8.8416, 'eval_samples_per_second': 115.364, 'eval_steps_per_second': 14.477, 'eval_num_tokens': 557081.0, 'eval_mean_token_accuracy': 0.9967003432102501, 'epoch': 6.996078431372549}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/peft/utils/save_and_load.py:230: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.0204, 'grad_norm': 8.861324310302734, 'learning_rate': 9.760529506232306e-06, 'num_tokens': 561771.0, 'mean_token_accuracy': 0.9949668951332569, 'epoch': 7.0588235294117645}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.0032, 'grad_norm': 5.142466068267822, 'learning_rate': 9.275001652656446e-06, 'num_tokens': 567940.0, 'mean_token_accuracy': 0.9984639473259449, 'epoch': 7.137254901960785}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.0068, 'grad_norm': 2.0268969535827637, 'learning_rate': 8.79909569745987e-06, 'num_tokens': 574239.0, 'mean_token_accuracy': 0.9978386223316192, 'epoch': 7.215686274509804}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.0052, 'grad_norm': 5.670112133026123, 'learning_rate': 8.333102840593015e-06, 'num_tokens': 580341.0, 'mean_token_accuracy': 0.9980004325509071, 'epoch': 7.294117647058823}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.0094, 'grad_norm': 0.12056846171617508, 'learning_rate': 7.877308216325222e-06, 'num_tokens': 586516.0, 'mean_token_accuracy': 0.9970464885234833, 'epoch': 7.372549019607844}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.0091, 'grad_norm': 3.0854196548461914, 'learning_rate': 7.43199071877525e-06, 'num_tokens': 592819.0, 'mean_token_accuracy': 0.9964757338166237, 'epoch': 7.450980392156863}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.0073, 'grad_norm': 0.12338008731603622, 'learning_rate': 6.997422831259992e-06, 'num_tokens': 599129.0, 'mean_token_accuracy': 0.9975929863750934, 'epoch': 7.529411764705882}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.0055, 'grad_norm': 7.058602809906006, 'learning_rate': 6.5738704595659065e-06, 'num_tokens': 605495.0, 'mean_token_accuracy': 0.9981589898467064, 'epoch': 7.607843137254902}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.0042, 'grad_norm': 0.36834171414375305, 'learning_rate': 6.161592769245114e-06, 'num_tokens': 611704.0, 'mean_token_accuracy': 0.9980905100703239, 'epoch': 7.686274509803922}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.0075, 'grad_norm': 5.247335433959961, 'learning_rate': 5.760842027035762e-06, 'num_tokens': 617863.0, 'mean_token_accuracy': 0.9959806442260742, 'epoch': 7.764705882352941}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.0082, 'grad_norm': 0.3110216557979584, 'learning_rate': 5.371863446503628e-06, 'num_tokens': 624084.0, 'mean_token_accuracy': 0.9975330494344234, 'epoch': 7.8431372549019605}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.0026, 'grad_norm': 0.05698874965310097, 'learning_rate': 4.9948950379995725e-06, 'num_tokens': 630299.0, 'mean_token_accuracy': 0.9987226195633412, 'epoch': 7.921568627450981}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.0059, 'grad_norm': 5.265107154846191, 'learning_rate': 4.630167463024393e-06, 'num_tokens': 636664.0, 'mean_token_accuracy': 0.9981288276612759, 'epoch': 8.0}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'eval_loss': 0.021350251510739326, 'eval_runtime': 8.8269, 'eval_samples_per_second': 115.556, 'eval_steps_per_second': 14.501, 'eval_num_tokens': 636664.0, 'eval_mean_token_accuracy': 0.9965486759319901, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/peft/utils/save_and_load.py:230: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.0078, 'grad_norm': 2.7353522777557373, 'learning_rate': 4.277903893090407e-06, 'num_tokens': 642953.0, 'mean_token_accuracy': 0.9978142060339451, 'epoch': 8.07843137254902}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.0045, 'grad_norm': 2.4751999378204346, 'learning_rate': 3.9383198731660655e-06, 'num_tokens': 649260.0, 'mean_token_accuracy': 0.9983835719525814, 'epoch': 8.156862745098039}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.0018, 'grad_norm': 2.0737662315368652, 'learning_rate': 3.611623189787103e-06, 'num_tokens': 655570.0, 'mean_token_accuracy': 0.9996323525905609, 'epoch': 8.235294117647058}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.0069, 'grad_norm': 0.24360327422618866, 'learning_rate': 3.2980137439149574e-06, 'num_tokens': 661767.0, 'mean_token_accuracy': 0.9963664911687374, 'epoch': 8.313725490196079}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.0035, 'grad_norm': 3.037841796875, 'learning_rate': 2.997683428620296e-06, 'num_tokens': 668027.0, 'mean_token_accuracy': 0.9990429885685443, 'epoch': 8.392156862745098}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.0049, 'grad_norm': 2.860004186630249, 'learning_rate': 2.7108160116663893e-06, 'num_tokens': 674263.0, 'mean_token_accuracy': 0.9973939344286918, 'epoch': 8.470588235294118}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.0037, 'grad_norm': 3.9214253425598145, 'learning_rate': 2.4375870230643417e-06, 'num_tokens': 680584.0, 'mean_token_accuracy': 0.9984392076730728, 'epoch': 8.549019607843137}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.0071, 'grad_norm': 2.5938820838928223, 'learning_rate': 2.178163647668771e-06, 'num_tokens': 686770.0, 'mean_token_accuracy': 0.9979091636836529, 'epoch': 8.627450980392156}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.0044, 'grad_norm': 0.8729494214057922, 'learning_rate': 1.9327046228798358e-06, 'num_tokens': 693000.0, 'mean_token_accuracy': 0.9977037698030472, 'epoch': 8.705882352941176}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.0064, 'grad_norm': 5.827888488769531, 'learning_rate': 1.7013601415141383e-06, 'num_tokens': 699124.0, 'mean_token_accuracy': 0.9970444709062576, 'epoch': 8.784313725490197}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.0042, 'grad_norm': 1.1232904195785522, 'learning_rate': 1.4842717599039047e-06, 'num_tokens': 705350.0, 'mean_token_accuracy': 0.9986020490527153, 'epoch': 8.862745098039216}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.0053, 'grad_norm': 10.024734497070312, 'learning_rate': 1.2815723112807266e-06, 'num_tokens': 711679.0, 'mean_token_accuracy': 0.9980051420629025, 'epoch': 8.941176470588236}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'eval_loss': 0.018350552767515182, 'eval_runtime': 8.8301, 'eval_samples_per_second': 115.514, 'eval_steps_per_second': 14.496, 'eval_num_tokens': 716247.0, 'eval_mean_token_accuracy': 0.996484852861613, 'epoch': 8.996078431372549}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/peft/utils/save_and_load.py:230: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.0015, 'grad_norm': 1.375266194343567, 'learning_rate': 1.093385824496815e-06, 'num_tokens': 717835.0, 'mean_token_accuracy': 0.9995370373129845, 'epoch': 9.019607843137255}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.0068, 'grad_norm': 4.679063320159912, 'learning_rate': 9.198274481335728e-07, 'num_tokens': 724009.0, 'mean_token_accuracy': 0.9964589715003968, 'epoch': 9.098039215686274}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.0021, 'grad_norm': 3.928658962249756, 'learning_rate': 7.610033800438344e-07, 'num_tokens': 730113.0, 'mean_token_accuracy': 0.9991620875895023, 'epoch': 9.176470588235293}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.0043, 'grad_norm': 3.3380768299102783, 'learning_rate': 6.170108023709348e-07, 'num_tokens': 736405.0, 'mean_token_accuracy': 0.997402760386467, 'epoch': 9.254901960784313}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.0033, 'grad_norm': 4.863052845001221, 'learning_rate': 4.879378220843667e-07, 'num_tokens': 742657.0, 'mean_token_accuracy': 0.9984322212636471, 'epoch': 9.333333333333334}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.0023, 'grad_norm': 0.0688590258359909, 'learning_rate': 3.7386341706841797e-07, 'num_tokens': 748997.0, 'mean_token_accuracy': 0.9992023803293705, 'epoch': 9.411764705882353}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.0033, 'grad_norm': 0.6801260113716125, 'learning_rate': 2.7485738779673143e-07, 'num_tokens': 755193.0, 'mean_token_accuracy': 0.9989131085574627, 'epoch': 9.490196078431373}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.0013, 'grad_norm': 0.12766961753368378, 'learning_rate': 1.9098031462242705e-07, 'num_tokens': 761513.0, 'mean_token_accuracy': 0.9997807018458843, 'epoch': 9.568627450980392}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.0072, 'grad_norm': 6.7950005531311035, 'learning_rate': 1.2228352070983719e-07, 'num_tokens': 767881.0, 'mean_token_accuracy': 0.9963426865637303, 'epoch': 9.647058823529411}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.0039, 'grad_norm': 4.67958402633667, 'learning_rate': 6.880904063063243e-08, 'num_tokens': 774093.0, 'mean_token_accuracy': 0.9979604668915272, 'epoch': 9.72549019607843}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.0044, 'grad_norm': 0.9790958762168884, 'learning_rate': 3.0589594643468114e-08, 'num_tokens': 780304.0, 'mean_token_accuracy': 0.9982920669019222, 'epoch': 9.803921568627452}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.0044, 'grad_norm': 0.062304019927978516, 'learning_rate': 7.64856867292163e-09, 'num_tokens': 786430.0, 'mean_token_accuracy': 0.9980943955481052, 'epoch': 9.882352941176471}\n",
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'loss': 0.004, 'grad_norm': 3.730623960494995, 'learning_rate': 0.0, 'num_tokens': 792699.0, 'mean_token_accuracy': 0.9981824323534966, 'epoch': 9.96078431372549}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/peft/utils/save_and_load.py:230: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'eval_loss': 0.018480965867638588, 'eval_runtime': 8.8516, 'eval_samples_per_second': 115.233, 'eval_steps_per_second': 14.461, 'eval_num_tokens': 792699.0, 'eval_mean_token_accuracy': 0.9966032239608467, 'epoch': 9.96078431372549}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/peft/utils/save_and_load.py:230: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self: <__main__.LossPlotCallback object at 0x7f9b55d3de70>\n",
      "logs: {'train_runtime': 2175.637, 'train_samples_per_second': 18.753, 'train_steps_per_second': 0.584, 'total_flos': 4.317586829155123e+16, 'train_loss': 0.34050214814726176, 'epoch': 9.96078431372549}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1270, training_loss=0.34050214814726176, metrics={'train_runtime': 2175.637, 'train_samples_per_second': 18.753, 'train_steps_per_second': 0.584, 'total_flos': 4.317586829155123e+16, 'train_loss': 0.34050214814726176})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T04:40:27.639214Z",
     "iopub.status.busy": "2025-05-10T04:40:27.639047Z",
     "iopub.status.idle": "2025-05-10T04:40:30.103311Z",
     "shell.execute_reply": "2025-05-10T04:40:30.102759Z",
     "shell.execute_reply.started": "2025-05-10T04:40:27.639197Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/peft/utils/save_and_load.py:230: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model('genshin-impact-role-model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T04:45:55.912846Z",
     "iopub.status.busy": "2025-05-10T04:45:55.912343Z",
     "iopub.status.idle": "2025-05-10T04:45:55.918168Z",
     "shell.execute_reply": "2025-05-10T04:45:55.917260Z",
     "shell.execute_reply.started": "2025-05-10T04:45:55.912805Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "message='行秋什么身份，他性格特征是什么'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T04:45:57.159638Z",
     "iopub.status.busy": "2025-05-10T04:45:57.159239Z",
     "iopub.status.idle": "2025-05-10T04:45:57.164822Z",
     "shell.execute_reply": "2025-05-10T04:45:57.163912Z",
     "shell.execute_reply.started": "2025-05-10T04:45:57.159599Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "chat=[{\"role\":\"user\",\"content\":message}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T04:40:30.113176Z",
     "iopub.status.busy": "2025-05-10T04:40:30.113030Z",
     "iopub.status.idle": "2025-05-10T04:40:31.175403Z",
     "shell.execute_reply": "2025-05-10T04:40:31.174847Z",
     "shell.execute_reply.started": "2025-05-10T04:40:30.113160Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): Qwen2ForCausalLM(\n",
       "      (model): Qwen2Model(\n",
       "        (embed_tokens): lora.Embedding(\n",
       "          (base_layer): Embedding(151666, 3584)\n",
       "          (lora_dropout): ModuleDict(\n",
       "            (default): Dropout(p=0.05, inplace=False)\n",
       "          )\n",
       "          (lora_A): ModuleDict()\n",
       "          (lora_B): ModuleDict()\n",
       "          (lora_embedding_A): ParameterDict(  (default): Parameter containing: [torch.cuda.FloatTensor of size 32x151666 (cuda:0)])\n",
       "          (lora_embedding_B): ParameterDict(  (default): Parameter containing: [torch.cuda.FloatTensor of size 3584x32 (cuda:0)])\n",
       "          (lora_magnitude_vector): ModuleDict()\n",
       "        )\n",
       "        (layers): ModuleList(\n",
       "          (0-27): 28 x Qwen2DecoderLayer(\n",
       "            (self_attn): Qwen2SdpaAttention(\n",
       "              (q_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=3584, out_features=3584, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3584, out_features=32, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=32, out_features=3584, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=3584, out_features=512, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3584, out_features=32, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=32, out_features=512, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=3584, out_features=512, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3584, out_features=32, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=32, out_features=512, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=3584, out_features=3584, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3584, out_features=32, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=32, out_features=3584, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (rotary_emb): Qwen2RotaryEmbedding()\n",
       "            )\n",
       "            (mlp): Qwen2MLP(\n",
       "              (gate_proj): Linear(in_features=3584, out_features=18944, bias=False)\n",
       "              (up_proj): Linear(in_features=3584, out_features=18944, bias=False)\n",
       "              (down_proj): Linear(in_features=18944, out_features=3584, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
       "            (post_attention_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
       "          )\n",
       "        )\n",
       "        (norm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
       "        (rotary_emb): Qwen2RotaryEmbedding()\n",
       "      )\n",
       "      (lm_head): lora.Linear(\n",
       "        (base_layer): Linear(in_features=3584, out_features=151666, bias=False)\n",
       "        (lora_dropout): ModuleDict(\n",
       "          (default): Dropout(p=0.05, inplace=False)\n",
       "        )\n",
       "        (lora_A): ModuleDict(\n",
       "          (default): Linear(in_features=3584, out_features=32, bias=False)\n",
       "        )\n",
       "        (lora_B): ModuleDict(\n",
       "          (default): Linear(in_features=32, out_features=151666, bias=False)\n",
       "        )\n",
       "        (lora_embedding_A): ParameterDict()\n",
       "        (lora_embedding_B): ParameterDict()\n",
       "        (lora_magnitude_vector): ModuleDict()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from  peft import PeftModel\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "#check_point='deepseek-ai/DeepSeek-R1-Distill-Qwen-7B'\n",
    "#tokenizer = AutoTokenizer.from_pretrained(check_point)\n",
    "#model = AutoModelForCausalLM.from_pretrained(check_point, torch_dtype=torch.float16,device_map=\"cuda\")\n",
    "\n",
    "#tokenizer.add_special_tokens({\n",
    "   # \"additional_special_tokens\": [\"<｜User｜>\", \"<｜Assistant｜>\"]\n",
    "#})\n",
    "#tokenizer.add_special_tokens({'pad_token': '<|pad|>'})\n",
    "#tokenizer.pad_token = '<|pad|>'\n",
    "#print(tokenizer.pad_token_id)\n",
    "#print(tokenizer.eos_token_id)\n",
    "#model.resize_token_embeddings(len(tokenizer))\n",
    "model=PeftModel.from_pretrained(model,'genshin-impact-role-model')\n",
    "model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T04:45:59.854948Z",
     "iopub.status.busy": "2025-05-10T04:45:59.854632Z",
     "iopub.status.idle": "2025-05-10T04:45:59.868989Z",
     "shell.execute_reply": "2025-05-10T04:45:59.868119Z",
     "shell.execute_reply.started": "2025-05-10T04:45:59.854924Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[151646, 151644,  22243, 100057,  99245, 101294,   3837,  42411, 102625,\n",
      "         104363, 102021, 151645, 151648,    198]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "prompt=tokenizer.apply_chat_template(chat,tokenize=True,add_generation_prompt=True,return_tensors='pt')\n",
    "prompt=prompt.to(model.device)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T04:46:01.145918Z",
     "iopub.status.busy": "2025-05-10T04:46:01.144753Z",
     "iopub.status.idle": "2025-05-10T04:46:01.616907Z",
     "shell.execute_reply": "2025-05-10T04:46:01.616389Z",
     "shell.execute_reply.started": "2025-05-10T04:46:01.145873Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151643\n",
      "151665\n"
     ]
    }
   ],
   "source": [
    "output=model.generate(prompt,\n",
    "    temperature=0.1,\n",
    "    top_p=0.1,\n",
    "    top_k=10,\n",
    "    max_length=512,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    pad_token_id=tokenizer.pad_token_id)\n",
    "print(tokenizer.eos_token_id)\n",
    "print(tokenizer.pad_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T04:46:03.289492Z",
     "iopub.status.busy": "2025-05-10T04:46:03.289221Z",
     "iopub.status.idle": "2025-05-10T04:46:03.294302Z",
     "shell.execute_reply": "2025-05-10T04:46:03.293617Z",
     "shell.execute_reply.started": "2025-05-10T04:46:03.289473Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "行秋什么身份，他性格特征是什么<think>\n",
      "行秋，行侠仗义的侠客\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(output[0],skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
